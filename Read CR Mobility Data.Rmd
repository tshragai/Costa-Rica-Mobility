---
title: "Costa Rica Mobility Read Data"
output: html_document
date: "2025-10-17"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r cars}
## upload necessary packages
library(sf)
library(terra)
library(tidyverse)
library(tigris)
library(data.table)
library(leaflet)
library(RColorBrewer)
library(slippymath)
library(scales)
## upload shapefile -- make this whatever polygon you want to extract to could be county or census tract
# california state parks shp (casp)
#casp_shp <- st_read("data/raw/parks/casp_individualpark_boundaries/ParkBoundaries.shp")

setwd("~/Downloads")
```



#Meta Activity Maps
- I only use visit_* tiles (not home_* tiles)
- I only use daytime observations (not nighttime)
##Step 1. Reduce memory burden
- the US csv file was quite large so I had to fiddle around with filtering/making sure my computer didn't explode (play around with this)


```{r}
library(data.table)

## -------- settings you can edit --------
input_dir   <- "~/Documents/CR meta mobility data"     
pattern     <- "\\.csv$"                          # only .csv files
chunk_size  <- 5000
lat_min <- 7.4; lat_max <- 11.4
lon_min <- -86.1; lon_max <- -82.8
country_filter <- "CR"
## --------------------------------------

csv_files <- list.files(input_dir, pattern = pattern, full.names = TRUE)

if (length(csv_files) == 0) {
  stop("No CSV files found in: ", input_dir)
}

# ----------------------------
# process a single CSV
# ----------------------------
process_one <- function(input_file, output_file) {
  # fresh output
  if (file.exists(output_file)) file.remove(output_file)
  
  con <- file(input_file, "r")
  on.exit(close(con), add = TRUE)
  
  header <- readLines(con, n = 1)
  if (length(header) == 0L) return(invisible(NULL))  # empty file
  
  repeat {
    chunk_lines <- readLines(con, n = chunk_size)
    if (length(chunk_lines) == 0L) break
    
    # build a small CSV string with header + this chunk
    chunk <- fread(paste(c(header, chunk_lines), collapse = "\n"))
    
    # filter + append to output
    chunk[
      visit_latitude  >= lat_min & visit_latitude  <= lat_max &
      visit_longitude >= lon_min & visit_longitude <= lon_max &
      country == country_filter
    ][
      , fwrite(.SD, output_file, append = TRUE)
    ]
  }
}

# ===========================================
##single combined output (optional)
# ===========================================
# Uncomment to produce one big file with all filtered rows
 combined_out <- file.path(input_dir, "all_processed_combined.csv")
 if (file.exists(combined_out)) file.remove(combined_out)
 for (infile in csv_files) {
   message("Appending from: ", basename(infile))
   # temp file for this input, then append to combined to keep logic clean
   tmp_out <- tempfile(fileext = ".csv")
   process_one(infile, tmp_out)
   if (file.exists(tmp_out) && file.info(tmp_out)$size > 0) {
     # copy header only once, then append rows
     if (!file.exists(combined_out)) {
       file.copy(tmp_out, combined_out)
     } else {
       # append without header: read tmp and write append
       dt <- fread(tmp_out)
       fwrite(dt, combined_out, append = TRUE)
     }
   }
   unlink(tmp_out)
 }

# ===========================================
# MODE A: per-file outputs (recommended)
# ===========================================
# Each input 'foo.csv' -> 'foo_processed.csv' in the same folder
for (infile in csv_files) {
  outfile <- sub("\\.csv$", "_processed.csv", infile)
  message("Processing: ", basename(infile), " -> ", basename(outfile))
  process_one(infile, outfile)
}
```

read in population data
```{r population data}
setwd("~/Costa-Rica-Mobility/Data")
pop_tiles <- st_read("costa_rica_activity_tiles_population.geojson")  

#worldpop or GHSL
pop_tiles <- pop_tiles %>%
  mutate(population_dif = worldpop_population - ghsl_population_2025) 

# Map difference in values
ggplot(pop_tiles) +
  geom_sf(aes(fill = population_dif), color = NA) +
  scale_fill_gradient2(
    name = "difference in population",
    midpoint = 0,
    low = "#2c7bb6", mid = "white", high = "#d7191c",
    oob = squish, limits = c(-1000, 1000)   # adjust limits as you like
  ) +
  labs(x = NULL, y = NULL) +
  theme_minimal()

#mmmmm they're pretty different

```

Trying to fix shit
```{r}

## --- Read in activity data ---
setwd("~/Downloads")
ca_data <- read.csv("all_processed_combined.csv")

# 1) Unique visit centroids in WGS84
pts_ll <- st_as_sf(
  ca_data %>% distinct(visit_longitude, visit_latitude),
  coords = c("visit_longitude","visit_latitude"),
  crs = 4326
)

# 2) Estimate grid step (meters) from nearest-neighbor distances
# Pairwise distances (n ~ 1k -> ~1e6 dists is fine)
M <- geosphere::distm(st_coordinates(pts_ll))  # meters
diag(M) <- Inf
nn <- apply(M, 1, min)                          # nearest neighbor for each point

# Focus on plausible tile spacing (e.g., 2â€“20 km band). Adjust if needed.
nn_band <- nn[nn >= 2000 & nn <= 20000]
stopifnot(length(nn_band) > 0)

grid_step_m <- median(nn_band, na.rm = TRUE)    # robust central tendency
cat("Estimated grid step (m):", round(grid_step_m), "\n")

# 3) Build squares centered on points with that side length (in a meters CRS)
crs_proj <- 5367  # Costa Rica TM Norte (meters)
pts_m <- st_transform(pts_ll, crs_proj)
XY <- st_coordinates(pts_m)

make_square <- function(x, y, s) {
  half <- s/2
  st_polygon(list(matrix(
    c(x-half, y-half,
      x+half, y-half,
      x+half, y+half,
      x-half, y+half,
      x-half, y-half),
    ncol = 2, byrow = TRUE
  )))
}

squares_m <- st_sfc(
  lapply(seq_len(nrow(XY)), function(i) make_square(XY[i,1], XY[i,2], grid_step_m)),
  crs = crs_proj
) |> st_sf()

# 4) Sanity: areas should be ~ grid_step_m^2
areas <- as.numeric(st_area(squares_m))
cat("Median area (m^2):", round(median(areas)), " | expected ~", round(grid_step_m^2), "\n")

# 5) To Leaflet (convert to lon/lat)
squares_ll <- st_transform(squares_m, 4326)

leaflet() %>%
  addTiles() %>%
  addPolygons(data = squares_ll, group = "Squares",
              color = "#e34a33", weight = 2, opacity = 1,
              fillColor = "#e34a33", fillOpacity = 0.35) %>%
  addCircleMarkers(data = pts_ll, group = "Centroids",
                   radius = 2.5, color = "#08519c", fillColor = "#08519c",
                   fillOpacity = 1, stroke = FALSE) 


## save output (unchanged file targets; rename if you want to distinguish weighted)
if (!dir.exists("data")) dir.create("data")
st_write(squares_ll, "data/costa_rica_activity_tiles.gpkg", delete_dsn = TRUE)

######################

# # ---------------------------
# # Bing / XYZ tile utilities
# # ---------------------------
# lonlat_to_tile_xyz <- function(lon, lat, z) {
#   n <- 2^z
#   x <- floor((lon + 180) / 360 * n)
#   lat_rad <- lat * pi/180
#   y <- floor((1 - log(tan(lat_rad) + 1/cos(lat_rad)) / pi) / 2 * n)
#   list(x = as.integer(x), y = as.integer(y))
# }
# 
# tile_bbox_xyz <- function(x, y, z) {
#   n <- 2^z
#   lon_min <- 360 * (x / n) - 180
#   lon_max <- 360 * ((x + 1) / n) - 180
#   tile2lat <- function(ty) 180/pi * atan(sinh(pi * (1 - 2 * ty / n)))
#   lat_max <- tile2lat(y)
#   lat_min <- tile2lat(y + 1)
#   list(xmin = lon_min, ymin = lat_min, xmax = lon_max, ymax = lat_max)
# }
# 
# tile_center_xyz <- function(x, y, z) {
#   b <- tile_bbox_xyz(x, y, z)
#   c(lon = (b$xmin + b$xmax)/2, lat = (b$ymin + b$ymax)/2)
# }
# 
# poly_from_bbox <- function(xmin, ymin, xmax, ymax) {
#   st_polygon(list(matrix(
#     c(xmin,ymin,  xmax,ymin,  xmax,ymax,  xmin,ymax,  xmin,ymin),
#     ncol = 2, byrow = TRUE
#   )))
# }
# 
# # ---------------------------
# # 1) Unique points (WGS84)
# # ---------------------------
# pts_ll <- st_as_sf(
#   ca_data %>% distinct(visit_longitude, visit_latitude),
#   coords = c("visit_longitude","visit_latitude"),
#   crs = 4326
# )
# 
# # ---------------------------
# # 2) Compute Bing z=13 tiles
# # ---------------------------
# z <- 13L
# 
# tiles_idx <- pts_ll %>%
#   st_coordinates() %>%
#   as.data.frame() %>%
#   rename(lon = X, lat = Y) %>%
#   rowwise() %>%
#   mutate(t = list(lonlat_to_tile_xyz(lon, lat, z)),
#          xtile = t$x, ytile = t$y) %>%
#   ungroup() %>%
#   distinct(xtile, ytile)
# 
# # Polygons for those tiles (WGS84)
# bb <- pmap(tiles_idx, ~ tile_bbox_xyz(..1, ..2, z))
# bb_df <- tibble::tibble(
#   xtile = tiles_idx$xtile,
#   ytile = tiles_idx$ytile,
#   xmin  = vapply(bb, `[[`, numeric(1), "xmin"),
#   ymin  = vapply(bb, `[[`, numeric(1), "ymin"),
#   xmax  = vapply(bb, `[[`, numeric(1), "xmax"),
#   ymax  = vapply(bb, `[[`, numeric(1), "ymax")
# )
# 
# tiles13_ll <- st_sf(
#   xtile = bb_df$xtile,
#   ytile = bb_df$ytile,
#   geometry = st_sfc(pmap(bb_df[,c("xmin","ymin","xmax","ymax")],
#                          ~ poly_from_bbox(..1, ..2, ..3, ..4)),
#                     crs = 4326)
# )
# 
# # True centers of those tiles (WGS84)
# centers_df <- tiles_idx %>%
#   rowwise() %>%
#   mutate(c = list(tile_center_xyz(xtile, ytile, z)),
#          lon = c["lon"], lat = c["lat"]) %>%
#   ungroup()
# 
# centers13_ll <- st_as_sf(centers_df, coords = c("lon","lat"), crs = 4326)
# 
# # ---------------------------
# # 3) Leaflet comparison map
# # ---------------------------
# leaflet() %>%
#   addTiles() %>%
#   addPolygons(data = tiles13_ll, group = "Bing tiles z=13",
#               color = "#2c7fb8", weight = 1.5, fill = FALSE, opacity = 0.9) %>%
#   #addCircleMarkers(data = centers13_ll, group = "z=13 tile centers",
#    #                radius = 2.5, color = "#2c7fb8",
#     #               fillColor = "#2c7fb8", fillOpacity = 1, stroke = FALSE) %>%
#   addCircleMarkers(data = pts_ll, group = "ca_data centroids",
#                    radius = 2.5, color = "#111111",
#                    fillColor = "#000000", fillOpacity = 1, stroke = FALSE) #%>%
#   #addPolygons(data = squares_ll, group = "Squares",
#    #           color = "#e34a33", weight = 2, opacity = 1,
#     #          fillColor = "#e34a33", fillOpacity = 0.35) 
#   


```

```{r}

## --- Read in activity data ---
setwd("~/Downloads")
ca_data <- read.csv("all_processed_combined.csv")

library(sf)
library(dplyr)

## --- Use your calculated tiles in pop_tiles ---
# pop_tiles must be sf with a polygon geometry
# and a population column we'll use for weighting.
pop_tiles <- pop_tiles %>%
  dplyr::rename(population = ghsl_population_2025)

# Ensure pop_tiles has a unique tile id
if (!("tile_id" %in% names(pop_tiles))) {
  pop_tiles <- pop_tiles %>% dplyr::mutate(tile_id = dplyr::row_number())
}

tiles_crs <- st_crs(pop_tiles)

## --- 1) Attach ORIGIN population by spatial join ---
home_sf <- st_as_sf(
  ca_data,
  coords = c("home_longitude", "home_latitude"),
  crs = 4326, remove = FALSE
) %>% st_transform(tiles_crs)

home_with_pop <- st_join(
  home_sf, pop_tiles[, c("tile_id","population")],
  join = st_within, left = TRUE
)

home_with_pop$origin_pop <- ifelse(is.na(home_with_pop$population), 0, home_with_pop$population)
home_with_pop$o_tile_id  <- home_with_pop$tile_id

home_info <- home_with_pop %>%
  st_drop_geometry() %>%
  dplyr::select(o_tile_id, origin_pop)

stopifnot(nrow(home_info) == nrow(ca_data))
ca_aug <- bind_cols(ca_data, home_info)

## --- 2) Assign DESTINATION tile (visit point -> destination tile) ---
visit_sf <- st_as_sf(
  ca_aug,
  coords = c("visit_longitude", "visit_latitude"),
  crs = 4326, remove = FALSE
) %>% st_transform(tiles_crs)

visit_with_tile <- st_join(
  visit_sf, pop_tiles[, c("tile_id")],
  join = st_within, left = TRUE
)

visit_info <- visit_with_tile %>%
  st_drop_geometry() %>%
  dplyr::mutate(d_tile_id = tile_id) %>%
  dplyr::select(d_tile_id)

stopifnot(nrow(visit_info) == nrow(ca_aug))
ca_aug <- bind_cols(ca_aug, visit_info)

## --- 3) Summarize population-weighted activity per destination tile ---
# Optional filter if you want only daytime:
# ca_aug <- dplyr::filter(ca_aug, day_or_night == "daytime")

### (A) Overall activity
tile_activity_overall <- ca_aug %>%
  dplyr::filter(!is.na(d_tile_id)) %>%
  dplyr::mutate(weighted_activity = visit_fraction * origin_pop) %>%
  dplyr::group_by(d_tile_id) %>%
  dplyr::summarise(activity = sum(weighted_activity, na.rm = TRUE), .groups = "drop")

### (B) Activity by ds
tile_activity_by_ds <- ca_aug %>%
  dplyr::filter(!is.na(d_tile_id)) %>%
  dplyr::mutate(weighted_activity = visit_fraction * origin_pop) %>%
  dplyr::group_by(d_tile_id, ds) %>%
  dplyr::summarise(activity = sum(weighted_activity, na.rm = TRUE), .groups = "drop")

## --- 4) Attach geometry (destination tiles) ---
tile_activity_overall_sf <- pop_tiles %>%
  dplyr::select(tile_id, geometry) %>%
  dplyr::right_join(tile_activity_overall, by = c("tile_id" = "d_tile_id"))

tile_activity_by_ds_sf <- pop_tiles %>%
  dplyr::select(tile_id, geometry) %>%
  dplyr::right_join(tile_activity_by_ds, by = c("tile_id" = "d_tile_id"))

## --- 5) Save outputs ---
if (!dir.exists("data")) dir.create("data")

st_write(tile_activity_overall_sf, "data/activity_by_pop_tiles_overall.gpkg", delete_dsn = TRUE)
st_write(tile_activity_by_ds_sf, "data/activity_by_pop_tiles_by_ds.gpkg", delete_dsn = TRUE)

# Optionally, also WGS84 for leaflet
tile_activity_overall_ll <- st_transform(tile_activity_overall_sf, 4326)
tile_activity_by_ds_ll <- st_transform(tile_activity_by_ds_sf, 4326)

st_write(tile_activity_overall_ll, "data/activity_by_pop_tiles_overall_wgs84.geojson", delete_dsn = TRUE)
st_write(tile_activity_by_ds_ll, "data/activity_by_pop_tiles_by_ds_wgs84.geojson", delete_dsn = TRUE)

```


##Step 3. Plot it in Leaflet
```{r}

tile_activity_lonlat<-tile_activity_ll%>%
  mutate(activity_log=log(activity+1))

# create color scale
pal <- colorNumeric("YlOrRd", domain = tile_activity_lonlat$activity_log, na.color = "transparent")
## create leaflet map
leaflet(tile_activity_lonlat) %>% 
  addTiles() %>% 
  addPolygons(fillColor = ~pal(activity_log),
              weight = 1, color = "black", fillOpacity = 0.7,
              popup = ~paste0("Activity", round(activity, 3))) %>% 
  addLegend(pal = pal, values = ~activity, title = "Activity Level", position = "bottomright")

# create color scale
pal <- colorNumeric("YlOrRd", domain = tile_activity_lonlat$activity, na.color = "transparent")
## create leaflet map
leaflet(tile_activity_lonlat) %>% 
  addTiles() %>% 
  addPolygons(fillColor = ~pal(activity),
              weight = 1, color = "black", fillOpacity = 0.7,
              popup = ~paste0("Activity", round(activity, 3))) %>% 
  addLegend(pal = pal, values = ~activity, title = "Activity Level", position = "bottomright")

 

```

```{r}


```




##Step 4. Summarize and merge with polygon boundary
- your CRS might be different (play around with st_valid() etc)
```{r}
#read in Costa Rica district data 
setwd("~/Downloads/CR_district_population_GHSL_2025")
districts <- st_read("CR_district_population_GHSL_2025.shp") %>%
  st_make_valid()

# Pick the column that identifies each district (edit this if different)
name_col <- "NOMB_UGED"   # e.g., "DISTRITO", "NAME", etc.

# Make sure districts share CRS with tiles for mapping
districts <- st_transform(districts, st_crs(tile_activity_lonlat))

# --- 2) Compute totals per district using area-aware overlay ---
# Work in a projected CRS for correct area math
tiles_m   <- st_transform(tile_activity_ll, 3857) %>%
  mutate(
    tile_area_m2     = as.numeric(st_area(geometry)),
    activity_density = activity / tile_area_m2   # activity per m^2
  )

districts_m <- st_transform(districts, 3857) %>%
  mutate(district_area_m2 = as.numeric(st_area(geometry)))

# Intersect tiles and districts
ix <- st_intersection(
  tiles_m %>% select(activity_density),
  districts_m %>% select(all_of(name_col), district_area_m2)
) %>%
  mutate(ix_area_m2 = as.numeric(st_area(geometry)))

# Summarize per district
district_activity <- ix %>%
  st_drop_geometry() %>%
  group_by(.data[[name_col]]) %>%
  summarise(
    total_activity           = sum(activity_density * ix_area_m2, na.rm = TRUE),        # âˆ‘ density Ã— area
    mean_activity_density_aw = total_activity / first(district_area_m2),                # area-weighted mean
    max_tile_density         = max(activity_density, na.rm = TRUE),                     # optional: max density tile overlapping district
    sd_tile_density          = sd(activity_density,  na.rm = TRUE),                     # optional: sd of tile densities
    .groups = "drop"
  )

# --- 3) Join back to polygons for mapping/exports ---
districts_with_activity <- districts %>%
  left_join(district_activity, by = setNames(name_col, name_col))

# Example: map with leaflet (uses lon/lat CRS)
pal <- colorNumeric("YlOrRd", domain = log(districts_with_activity$total_activity+1))
 leaflet(districts_with_activity) %>%
   addTiles() %>%
   addPolygons(fillColor = ~pal(log(total_activity+1)), color = "#333", weight = 0.5,
               fillOpacity = 0.7
               ) 


 
 
 # log-transform then stretch domain
vals <- log1p(districts_with_activity$total_activity)
pal <- colorNumeric(
  palette = "YlOrRd",
  domain  = range(vals, na.rm = TRUE),
  na.color = "transparent"
)

leaflet(districts_with_activity) %>%
  addTiles() %>%
  addPolygons(
    fillColor   = ~pal(log1p(total_activity)),
    color       = "#333",
    weight      = 0.5,
    fillOpacity = 0.8
  ) %>%
  addLegend(
    pal     = pal,
    values  = vals,
    title   = "log(total activity + 1)",
    position = "bottomright"
  )

vals <- log1p(districts_with_activity$total_activity)
pal <- colorBin(
  palette = "YlOrRd",
  domain  = vals,
  bins    = 7,          # fewer bins = bigger visible jumps
  na.color = "transparent"
)

pal <- colorNumeric(
  palette = "viridis",   # or "magma", "plasma", "viridis"
  domain  = log1p(districts_with_activity$total_activity),
  na.color = "transparent"
)

## save output (unchanged file targets; rename if you want to distinguish weighted)
if (!dir.exists("data")) dir.create("data")
st_write(districts_with_activity, "data/Costa_Rica_districts_activity.gpkg", delete_dsn = TRUE)
```

