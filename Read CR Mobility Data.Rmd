---
title: "Costa Rica Mobility Read Data"
output: html_document
date: "2025-10-17"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Set libraries and working directory
```{r set up}
## upload necessary packages
library(sf)
library(terra)
library(tidyverse)
library(tigris)
library(data.table)
library(leaflet)
library(RColorBrewer)
library(slippymath)
library(scales)
setwd("~/Downloads")
```



#Meta Activity Maps
- I only use visit_* tiles (not home_* tiles)
- I only use daytime observations (not nighttime)
##Step 1. Reduce memory burden
- the US csv file was quite large so I had to fiddle around with filtering/making sure my computer didn't explode (play around with this)
##This is Sam's workflow, works great!

```{r read data}
library(data.table)

## -------- settings you can edit --------
input_dir   <- "~/Documents/CR meta mobility data"     
pattern     <- "\\.csv$"                          # only .csv files
chunk_size  <- 5000
lat_min <- 7.4; lat_max <- 11.4
lon_min <- -86.1; lon_max <- -82.8
country_filter <- "CR"
## --------------------------------------

csv_files <- list.files(input_dir, pattern = pattern, full.names = TRUE)

if (length(csv_files) == 0) {
  stop("No CSV files found in: ", input_dir)
}

# ----------------------------
# process a single CSV
# ----------------------------
process_one <- function(input_file, output_file) {
  # fresh output
  if (file.exists(output_file)) file.remove(output_file)
  
  con <- file(input_file, "r")
  on.exit(close(con), add = TRUE)
  
  header <- readLines(con, n = 1)
  if (length(header) == 0L) return(invisible(NULL))  # empty file
  
  repeat {
    chunk_lines <- readLines(con, n = chunk_size)
    if (length(chunk_lines) == 0L) break
    
    # build a small CSV string with header + this chunk
    chunk <- fread(paste(c(header, chunk_lines), collapse = "\n"))
    
    # filter + append to output
    chunk[
      visit_latitude  >= lat_min & visit_latitude  <= lat_max &
      visit_longitude >= lon_min & visit_longitude <= lon_max &
      country == country_filter
    ][
      , fwrite(.SD, output_file, append = TRUE)
    ]
  }
}

# ===========================================
##single combined output (optional)
# ===========================================
# Uncomment to produce one big file with all filtered rows
 combined_out <- file.path(input_dir, "all_processed_combined.csv")
 if (file.exists(combined_out)) file.remove(combined_out)
 for (infile in csv_files) {
   message("Appending from: ", basename(infile))
   # temp file for this input, then append to combined to keep logic clean
   tmp_out <- tempfile(fileext = ".csv")
   process_one(infile, tmp_out)
   if (file.exists(tmp_out) && file.info(tmp_out)$size > 0) {
     # copy header only once, then append rows
     if (!file.exists(combined_out)) {
       file.copy(tmp_out, combined_out)
     } else {
       # append without header: read tmp and write append
       dt <- fread(tmp_out)
       fwrite(dt, combined_out, append = TRUE)
     }
   }
   unlink(tmp_out)
 }

# ===========================================
# MODE A: per-file outputs (recommended)
# ===========================================
# Each input 'foo.csv' -> 'foo_processed.csv' in the same folder
for (infile in csv_files) {
  outfile <- sub("\\.csv$", "_processed.csv", infile)
  message("Processing: ", basename(infile), " -> ", basename(outfile))
  process_one(infile, outfile)
}
```

